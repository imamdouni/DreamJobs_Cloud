{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-24T08:33:21.519940500Z",
     "start_time": "2023-08-24T08:33:19.077665400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fertig\n"
     ]
    }
   ],
   "source": [
    "## Import der Module\n",
    "# Pyhton             Version 3.11.1\n",
    "# Selenium           Version 4.9.1\n",
    "# webdriver_manager  Version 3.8.6\n",
    "# pandas             Version  2.0.1\n",
    "# datetime           Version 5.1\n",
    "# sqlalchemy         Version 2.0.13\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "#---------------------------------------------------------------------------\n",
    "## Hilfsfunktionen\n",
    "# Log File\n",
    "def schreibe_log_file(log_eintrag):\n",
    "    datei='log-Indeed.txt' # Name der Log-Datei\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    # Überprüfen, ob die Log-Datei bereits existiert\n",
    "    if not os.path.exists(datei):\n",
    "        # Wenn die Log-Datei nicht existiert, wird sie erstellt und der Log-Eintrag wird hineingeschrieben\n",
    "        with open(datei, 'w') as file:\n",
    "            file.write(f\"{timestamp}, {log_eintrag}\" + '\\n')\n",
    "    else:\n",
    "        # Wenn die Log-Datei bereits existiert, wird der Log-Eintrag an das Ende der Datei angehängt\n",
    "        with open(datei, 'a') as file:\n",
    "            file.write(f\"{timestamp}, {log_eintrag}\" + '\\n')\n",
    "# E-Mail - Benachrichtigung bei Fehlern\n",
    "def schreibe_e_mail(message, Subject=\"fehlerhaft\"):\n",
    "    # SMTP-Server-Konfiguration\n",
    "    host = \"smtp.web.de\"###imap.web.de\n",
    "    port = 587\n",
    "    log_in_id = \"dc-jobs\"\n",
    "    passwort = \"DatacraftKurs0822!\"\n",
    "    # Erstellen der E-Mail-Nachricht\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = log_in_id + \"@web.de\" # Absender\n",
    "    msg['To'] = \"jobs@data-craft.de\" # Empfänger\n",
    "    msg['Subject'] = f'Indeed Abfrage {Subject}' # Betreff der E-Mail\n",
    "    msg.attach(MIMEText(message, 'plain')) # Hinzufügen des Nachrichtentextes zur E-Mail\n",
    "    # Verbindung zum SMTP-Server herstellen und E-Mail senden\n",
    "    with smtplib.SMTP(host=host, port=port) as mail:\n",
    "        mail.starttls() # Starte TLS-Verschlüsselung\n",
    "        mail.login(log_in_id, passwort) # Anmeldung am SMTP-Server\n",
    "        mail.send_message(msg) # E-Mail senden\n",
    "# random Wartezeit zum für seitenaufbau oder so\n",
    "def wartezeit(zeit=3):\n",
    "    \"\"\"\n",
    "    Diese Funktion fügt eine zufällige Wartezeit hinzu, bevor sie fortgesetzt wird.\n",
    "    :param zeit: Die maximale Wartezeit in Sekunden (Standardwert ist 3).\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    time.sleep(random.randint(1, zeit))\n",
    "#-------------------------------------------------------------------------------\n",
    "## SQL-Server verbindung erstellen\n",
    "# SQL-Server-Konfiguration\n",
    "#host=\"datacraft-db.cf3hyz1fwdiw.eu-central-1.rds.amazonaws.com\"\n",
    "host='datacraft-jobs.postgres.database.azure.com'\n",
    "database=\"postgres\"\n",
    "user=\"jobs_rw\"\n",
    "password=\"01QT3X48xCi4KXUckxDq\"\n",
    "tabelle_Rohdaten=\"jobs.rohdaten\"\n",
    "# Erstelle eine SQL-Verbindung mit der Datenbank\n",
    "connection = create_engine(f'postgresql+psycopg2://{user}:{password}@{host}/{database}')\n",
    "#-------------------------------------------------------------------------------\n",
    "## Der Scraper\n",
    "def scraper(jobtitel, suchort='Deutschland'):\n",
    "    '''\n",
    "    Der eigentliche Scraper für die Seite\n",
    "   \n",
    "    :param jobtitel: Der Titel des Jobs, nach dem gesucht werden soll.\n",
    "    :param suchort: Der Ort, an dem nach Jobs gesucht werden soll. Standardwert ist 'Deutschland'.\n",
    "    '''\n",
    "   \n",
    "    schreibe_log_file(f'suche nach {jobtitel}')\n",
    "    # ChromeOptions erstellen\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    #Headless-Modus aktivieren\n",
    "    #chrome_options.add_argument(\"--headless\")##### hier war auskommentiert hier ohne zu sehen der webseite alles passiert im hintergrund\n",
    "    # Browserfenster öffnen nach Einstellung in den Optionen\n",
    "    try:\n",
    "        #driver_path = ChromeDriverManager().install()  #Neu: Chromedriver herunterladen und den Pfad\n",
    "        #service = ChromeService(executable_path=driver_path)  # Neu: ChromeService mit dem Pfad erstellen\n",
    "        #driver = webdriver.Chrome(service=service, options=chrome_options)  # Neu: Initialisiere den Chromedriver mit den Optionen\n",
    "        #schreibe_log_file('Browser geoeffnet')# neu eingesetzt kann aber raus\n",
    "        #driver_path = ChromeDriverManager().install()  #Neu: Chromedriver herunterladen und den Pfad\n",
    "        driver = webdriver.Chrome(options=chrome_options)  # Neu: Initialisiere den Chromedriver mit den Optionen\n",
    "        #driver.service.path = driver_path  # Neu: Setze den Pfad des Dienstes auf den heruntergeladenen #Chromedriver\n",
    "        schreibe_log_file('Browser geoeffnet')\n",
    "        # das war alt\n",
    "        #driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), #options=chrome_options)\n",
    "        #schreibe_log_file('Browser geoeffnet')\n",
    "    except:\n",
    "        schreibe_log_file('Browser konnte nicht geoeffnet werden')\n",
    "        schreibe_e_mail(f'Browser konnte nicht geoeffnet werden: -- {datetime.datetime.now().strftime(\"%d.%m.%Y, %H:%M:%S\")} --')\n",
    "    # Webseite aufrufen\n",
    "    wartezeit(3)\n",
    "    driver.get(\"https://www.indeed.de/\")\n",
    "    # Fenster Maximieren\n",
    "    driver.maximize_window() # evtl. wenn Headless-Modus aktiv ist auskommentieren  ### habe auskommentiert schau ob klappt\n",
    "    #------------------------------------------------------------------------------\n",
    "    ## Cookies akzeptieren\n",
    "    wartezeit(3)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"onetrust-accept-btn-handler\"]').click()\n",
    "    except:\n",
    "        pass\n",
    "    wartezeit(3)\n",
    "    #------------------------------------------------------------------------------\n",
    "    ## Suchfelder finden, anwählen und befüllen\n",
    "    # Suchfeld Jobbezeichnung -> finden und befüllen\n",
    "    try:\n",
    "        suchfeld_jobtitel=driver.find_element(By.XPATH,'//*[@id=\"text-input-what\"]')\n",
    "        suchfeld_jobtitel.send_keys(jobtitel)\n",
    "        wartezeit(3)\n",
    "    # Suchfeld Ort -> finden und befüllen\n",
    "        suchfeld_ort=driver.find_element(By.XPATH,'//*[@id=\"text-input-where\"]')\n",
    "        suchfeld_ort.send_keys(suchort)\n",
    "        # Anfrage mit Enter/Return abschicken\n",
    "        suchfeld_ort.send_keys(Keys.RETURN)\n",
    "    except:\n",
    "        schreibe_log_file(f'Suchdaten eingeben nicht möglich: Jobtitel:-{jobtitel}; Suchort-{suchort}')\n",
    "        print(f'Suchdaten eingeben nicht möglich: Jobtitel:-{jobtitel}; Suchort-{suchort}')\n",
    "        return\n",
    "    wartezeit(3)\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## nach Datum sortieren\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"jobsearch-JapanPage\"]/div/div/div[5]/div[1]/div[4]/div/div/div[1]/span[2]/a').click()\n",
    "    wartezeit(3)\n",
    "    #-----------------------------------------------------------------------------\n",
    "    ## einblendung entfernen\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, '//*[@id=\"mosaic-desktopserpjapopup\"]/div[1]/button').click()\n",
    "    except:\n",
    "        pass\n",
    "    wartezeit(3)\n",
    "    #-----------------------------------------------------------------------------\n",
    "    link_liste_scraped=[]\n",
    "    ## link_liste_scraped befüllen von erster Seite\n",
    "    anzeigen=driver.find_elements(By.CLASS_NAME, 'jcs-JobTitle')\n",
    "    for anzeige in anzeigen:\n",
    "        link_liste_scraped.append(anzeige.get_attribute('href'))\n",
    "    # auf \"nächste Seite\" Button klicken\n",
    "    try:\n",
    "        driver.find_element(By.XPATH , '//*[@id=\"jobsearch-JapanPage\"]/div/div/div[5]/div[1]/nav/div[6]/a').click()\n",
    "    except:\n",
    "        pass\n",
    "    #--------------------------------------------------------------------------------\n",
    "    ## von weiter Seiten die Links holen\n",
    "    for i in range(9):\n",
    "        anzeigen=driver.find_elements(By.CLASS_NAME, 'jcs-JobTitle')\n",
    "        for anzeige in anzeigen:\n",
    "            link_liste_scraped.append(anzeige.get_attribute('href'))\n",
    "        # auf \"nächste Seite\" Button klicken\n",
    "        try:\n",
    "            driver.find_element(By.XPATH , '//*[@id=\"jobsearch-JapanPage\"]/div/div/div[5]/div[1]/nav/div[7]/a').click()\n",
    "        except:\n",
    "            pass\n",
    "        wartezeit()\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # überprüfen ob link_liste_scraped leer ist da evtl. die Class name geändert wurde\n",
    "    if len(link_liste_scraped) == 0:\n",
    "        schreibe_log_file('Keine Links auf gefunden')\n",
    "        schreibe_e_mail('Keine Links auf Webseite gefunden:\\n\\n Hinweis: Classenname überprüfen für alle Stellenanzeigen!')\n",
    "        return\n",
    "    else:\n",
    "        pass\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # Duplikate entfernen\n",
    "    link_liste_scraped_ohne_duplikate = list(set(link_liste_scraped))\n",
    "    schreibe_log_file(f'Es wurden {len(link_liste_scraped)-len(link_liste_scraped_ohne_duplikate)} Duplikate in der \"Link Liste\" entfernt')\n",
    "    schreibe_log_file(\"link liste erstellt\")\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # Lese die bestehenden URLs aus der Datenbank\n",
    "    existing_urls = pd.read_sql_query(f\"SELECT url FROM {tabelle_Rohdaten}\", connection)\n",
    "    schreibe_log_file(f'{len(existing_urls)} in der datenbak bereits vorhanden')\n",
    "    # Filtere den DataFrame, um nur neue URLs zu behalten\n",
    "    link_liste = [url for url in link_liste_scraped_ohne_duplikate if url not in existing_urls['url'].values]\n",
    "    #--------------------------------------------------------------------------------\n",
    "    seiten_inhalt_html_liste = []\n",
    "    seiten_inhalt_liste = []\n",
    "    URL_Liste = []\n",
    "    Datum_Liste = []\n",
    "    try:\n",
    "        schreibe_log_file('Abfrage begonnen')\n",
    "        for link in link_liste:\n",
    "            # link öffnen\n",
    "            driver.get(link)\n",
    "            wartezeit()\n",
    "            # scrapen der daten und befüllen der Listen\n",
    "            seiten_inhalt_html_liste.append(driver.find_element(By.CLASS_NAME, 'jobsearch-JobComponent').get_attribute('innerHTML'))\n",
    "            seiten_inhalt_liste.append(driver.find_element(By.CLASS_NAME, 'jobsearch-JobComponent').text)\n",
    "            URL_Liste.append(link)\n",
    "            Datum_Liste.append(datetime.datetime.now())\n",
    "            schreibe_log_file(f'Daten wurden gezogen: {link}')\n",
    "            wartezeit(5)\n",
    "    except:\n",
    "        schreibe_log_file(\"Abfrage abgebrochen !!!\")\n",
    "        schreibe_e_mail(f\"Die Abfrage wurde abgebrochen. -- {datetime.datetime.now()} --\")\n",
    "        schreibe_log_file('Abfrage beendet')\n",
    "    #----------------------------------------------------------------------------------\n",
    "    # Schließen des Browsers\n",
    "    wartezeit(1)\n",
    "    driver.quit()\n",
    "    schreibe_log_file('Browser geschlossen')\n",
    "    #----------------------------------------------------------------------------------\n",
    "    # überprüfen ob die Listen gleich lang sind und den DataFrame erstellen\n",
    "    if len(set(map(len, [seiten_inhalt_html_liste,\n",
    "                        seiten_inhalt_liste,\n",
    "                        URL_Liste,\n",
    "                        Datum_Liste]))) > 1:\n",
    "        schreibe_log_file('Listen sind verschieden lang')\n",
    "        schreibe_e_mail('Listen sind nicht gleich lang')\n",
    "        return\n",
    "    else:\n",
    "        # DataFrame erstellen\n",
    "        df = pd.DataFrame({\"seite\": \"indeed\",\n",
    "                        \"seiten_inhalt_html\": seiten_inhalt_html_liste,\n",
    "                        \"seiten_inhalt\": seiten_inhalt_liste,\n",
    "                        \"url\": URL_Liste,\n",
    "                        \"datum\":Datum_Liste,\n",
    "                        \"storno\": False})\n",
    "    #-----------------------------------------------------------------------------------\n",
    "    ## Daten in die Datenbank einfügen\n",
    "    # Schreibe den bereinigten DataFrame in die Datenbank\n",
    "    df.to_sql(name=tabelle_Rohdaten.split('.')[1],\n",
    "            schema=tabelle_Rohdaten.split('.')[0],\n",
    "            con=connection, if_exists='append', index=False, )\n",
    "    schreibe_log_file(f'Es wurden {len(df)} Daten von Indeed hinzugefügt')\n",
    "    # Verbindung zur SQL-Datenbank schließen\n",
    "    connection.dispose()\n",
    "print(\"fertig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d3782078f379f922"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "scraper(\"Data Analyst\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T08:36:08.868938800Z",
     "start_time": "2023-08-24T08:33:25.901702500Z"
    }
   },
   "id": "27a10ae76819ca64"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                  Jobtitel\n0                    Customer Data Analyst\n1                             Data Analyst\n2                      Junior Data Analyst\n3                    (Junior) Data Analyst\n4                             Datenanalyst\n5          Data Engineer / Digital Analyst\n6              BI Analyst* / Data Analyst*\n7           Datenbankentwickler / -analyst\n8   Data Analytics & Visualization Analyst\n9                          BI Data Analyst\n10           Junior Data Scientist/Analyst\n11                Reporting & Data Analyst",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Jobtitel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Customer Data Analyst</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Data Analyst</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Junior Data Analyst</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(Junior) Data Analyst</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Datenanalyst</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Data Engineer / Digital Analyst</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>BI Analyst* / Data Analyst*</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Datenbankentwickler / -analyst</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Data Analytics &amp; Visualization Analyst</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>BI Data Analyst</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Junior Data Scientist/Analyst</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Reporting &amp; Data Analyst</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ich arbeite mit zwei Computern, und leider hat die Datei für die Suchbegriffe (Jobtitel) jeweils ein anderen Speicherort\n",
    "try:\n",
    "    suchbegriffe = pd.read_excel(r\"C:\\Users\\Admin\\Documents\\DreamJobs\\Benötigte Dateien\\Jobtitel.xlsx\",\n",
    "      sheet_name='Indeed')\n",
    "except:\n",
    "    suchbegriffe = pd.read_excel(r\"C:\\Users\\Admin\\Documents\\DreamJobs\\Benötigte Dateien\\Jobtitel.xlsx\",\n",
    "     sheet_name='Indeed')  \n",
    "display(suchbegriffe)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T08:36:22.960148400Z",
     "start_time": "2023-08-24T08:36:19.361515200Z"
    }
   },
   "id": "4480e9aaae87a146"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 Jobtitel gefunden\n",
      "0: Suche nach \"Customer Data Analyst\", Start: 10:36:28 Uhr\n",
      "1: Suche nach \"Data Analyst\", Start: 10:40:04 Uhr\n",
      "2: Suche nach \"Junior Data Analyst\", Start: 10:42:03 Uhr\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'driver' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, jobtitel \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(suchbegriffe\u001B[38;5;241m.\u001B[39mJobtitel):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: Suche nach \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjobtitel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, Start: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdatetime\u001B[38;5;241m.\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM:\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Uhr\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mscraper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjobtitel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfertig\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[1], line 107\u001B[0m, in \u001B[0;36mscraper\u001B[1;34m(jobtitel, suchort)\u001B[0m\n\u001B[0;32m    105\u001B[0m \u001B[38;5;66;03m# Webseite aufrufen\u001B[39;00m\n\u001B[0;32m    106\u001B[0m wartezeit(\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m--> 107\u001B[0m \u001B[43mdriver\u001B[49m\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://www.indeed.de/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# Fenster Maximieren\u001B[39;00m\n\u001B[0;32m    109\u001B[0m driver\u001B[38;5;241m.\u001B[39mmaximize_window() \u001B[38;5;66;03m# evtl. wenn Headless-Modus aktiv ist auskommentieren  ### habe auskommentiert schau ob klappt\u001B[39;00m\n",
      "\u001B[1;31mUnboundLocalError\u001B[0m: cannot access local variable 'driver' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "print(f'{len(suchbegriffe)} Jobtitel gefunden')\n",
    "for i, jobtitel in enumerate(suchbegriffe.Jobtitel):\n",
    "    print(f'{i}: Suche nach \"{jobtitel}\", Start: {datetime.datetime.now().strftime(\"%H:%M:%S\")} Uhr')\n",
    "    scraper(jobtitel)\n",
    "print(\"\")\n",
    "print(\"fertig\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T08:42:22.038376800Z",
     "start_time": "2023-08-24T08:36:28.772932300Z"
    }
   },
   "id": "fb552850dc62cf1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T14:07:47.405228100Z",
     "start_time": "2023-08-22T14:07:47.379310600Z"
    }
   },
   "id": "d36d08bbcb860314"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-22T14:07:47.395182800Z"
    }
   },
   "id": "ba847b1b401a8ce1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
